{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer - Attention is all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6d91664310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 128\n",
    "# Semilla\n",
    "torch.manual_seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PositionalEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__ (self, d_model, max_seq_len=MAX_SEQ_LEN):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n",
    "        token_pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() \n",
    "                             * (-math.log(10000.0) / d_model))\n",
    "        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n",
    "        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n",
    "        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pos_embed_matrix[:x.size(0), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### PositionFeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear2(F.gelu(self.linear1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model=512, n_heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_model % n_heads == 0, 'Embedding size not compatible with number of heads'\n",
    "        \n",
    "        self.d_v = d_model // n_heads\n",
    "        self.d_k = self.d_v\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)    \n",
    "    \n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        '''\n",
    "        Q, K, V: [batch_size, seq_len, d_model(n_heads*d_k)]\n",
    "        after transpose Q, K, V: [batch_size, n_heads, seq_len, d_k]\n",
    "        '''\n",
    "        batch_size = Q.size(0)\n",
    "        \n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(V).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        weighted_values, attention = self.scaled_dot_product(Q, K, V, mask)\n",
    "        \n",
    "        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_k)\n",
    "        weighted_values = self.W_o(weighted_values)\n",
    "        \n",
    "        return weighted_values, attention\n",
    "        \n",
    "        \n",
    "        \n",
    "    def scaled_dot_product(self, Q, K, V, mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        weighted_values = torch.matmul(attention, V)\n",
    "        \n",
    "        return weighted_values, attention\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncoderSubLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.droupout1 = nn.Dropout(dropout)\n",
    "        self.droupout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask = None):\n",
    "        attention_score, _ = self.self_attn(x, x, x, mask)\n",
    "        x = x + self.droupout1(attention_score)\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.droupout2(self.ffn(x))\n",
    "        return self.norm2(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_head, dim_feedforward, num_layers, dropout=0.1):\n",
    "         super().__init__()\n",
    "         \n",
    "         self.layers = nn.ModuleList([EncoderSubLayer(d_model, n_head, dim_feedforward, dropout) for _ in range(num_layers)])\n",
    "         self.norm = nn.LayerNorm(d_model)\n",
    "         \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "            \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecoderSubLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.feed_forward = PositionFeedForward(d_model, dim_feedforward)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n",
    "        attention_score, _ = self.self_attn(x, x, x, mask=target_mask)\n",
    "        x = x + self.dropout1(attention_score)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        encoder_attention_score, _ = self.cross_attn(x, encoder_output, encoder_output, mask=encoder_mask)\n",
    "        x = x + self.dropout2(encoder_attention_score)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        feed_forward_output = self.feed_forward(x)\n",
    "        x = x + self.dropout3(feed_forward_output)\n",
    "        x = self.norm3(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__ (self, d_model, n_head, dim_feedforward, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([DecoderSubLayer(d_model, n_head, dim_feedforward, dropout) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, encoder_output, target_mask, encoder_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, target_mask, encoder_mask)\n",
    "            \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "                self, \n",
    "                d_model, \n",
    "                n_head, \n",
    "                dim_feedforward, \n",
    "                num_layers, \n",
    "                input_vocab_size,\n",
    "                target_vocab_size,\n",
    "                max_seq_len=MAX_SEQ_LEN,\n",
    "                dropout=0.1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_embedding = PositionalEmbedding(d_model, max_seq_len)\n",
    "        self.encoder = Encoder(d_model, n_head, dim_feedforward, num_layers, dropout)\n",
    "        self.decoder = Decoder(d_model, n_head, dim_feedforward, num_layers, dropout)\n",
    "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, source, target):\n",
    "        # Enconder mask\n",
    "        encoder_mask, target_mask = self.mask(source, target)\n",
    "        # Embedding and positional embedding\n",
    "        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n",
    "        source = self.pos_embedding(source)\n",
    "        # Encoder\n",
    "        encoder_output = self.encoder(source, encoder_mask)\n",
    "        \n",
    "        # Decoder embedding and positional encoding\n",
    "        target = self.decoder_embedding(target) * math.sqrt(self.encoder_embedding.embedding_dim)\n",
    "        target = self.pos_embedding(target)\n",
    "        # Decoder\n",
    "        decoder_output = self.decoder(target, encoder_output, target_mask, encoder_mask)\n",
    "        \n",
    "        return self.output_layer(decoder_output)\n",
    "        \n",
    "    \n",
    "    def mask(self, source, target):\n",
    "        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n",
    "        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n",
    "        size = target.size(1)\n",
    "        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n",
    "        target_mask = target_mask & no_mask\n",
    "        \n",
    "        return source_mask, target_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_source = 10\n",
    "seq_len_target = 10\n",
    "batch_size = 2\n",
    "input_vocab_size = 50\n",
    "target_vocab_size = 50\n",
    "\n",
    "source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\n",
    "target = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))\n",
    "\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "d_ff = 2048\n",
    "num_layers = 6\n",
    "\n",
    "model = Transformer(d_model, \n",
    "                n_heads, \n",
    "                d_ff, \n",
    "                num_layers, \n",
    "                input_vocab_size,\n",
    "                target_vocab_size,\n",
    "                max_seq_len=MAX_SEQ_LEN,\n",
    "                dropout=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "source = source.to(device)\n",
    "target = target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouput.shape torch.Size([2, 10, 50])\n"
     ]
    }
   ],
   "source": [
    "# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\n",
    "print(f'ouput.shape {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# English to Spanish Translation -  Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['OK.', '¡Órale!'],\n",
       " ['No.', 'No.'],\n",
       " ['Go!', '¡Ya!'],\n",
       " ['No!', '¡No!'],\n",
       " ['Go!', '¡Fuera!'],\n",
       " ['Ah!', '¡Anda!'],\n",
       " ['Ow!', '¡Ay!'],\n",
       " ['Go!', '¡Sal!'],\n",
       " ['Hi.', '¡Hola!'],\n",
       " ['Go.', 'Vete.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"../Transformer/resources/eng-spa.txt\"\n",
    "\n",
    "with open(PATH, 'r', encoding='utf-8')  as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]\n",
    "\n",
    "eng_spa_pairs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OK.', 'No.', 'Go!', 'No!', 'Go!']\n",
      "['¡Órale!', 'No.', '¡Ya!', '¡No!', '¡Fuera!']\n"
     ]
    }
   ],
   "source": [
    "eng_sentences = [pair[0] for pair in eng_spa_pairs]\n",
    "spa_sentences = [pair[1] for pair in eng_spa_pairs]\n",
    "\n",
    "print(eng_sentences[:5])\n",
    "print(spa_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Hola cómo estás?1@2\n",
      "<sos> hola como estas <eos>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[\" \"]+', ' ', sentence)\n",
    "    sentence = re.sub(r'[á]+', 'a', sentence)\n",
    "    sentence = re.sub(r'[é]+', 'e', sentence)\n",
    "    sentence = re.sub(r'[í]+', 'i', sentence)\n",
    "    sentence = re.sub(r'[ó]+', 'o', sentence)\n",
    "    sentence = re.sub(r'[ú]+', 'u', sentence)\n",
    "    sentence = re.sub(r'[^a-z]+', ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<sos> ' + sentence + ' <eos>'\n",
    "    return sentence\n",
    "\n",
    "s1 = \"¿Hola cómo estás?1@2\"\n",
    "print(s1)\n",
    "print(preprocess_sentence(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos> ok <eos>', '<sos> no <eos>', '<sos> go <eos>', '<sos> no <eos>', '<sos> go <eos>']\n",
      "['<sos> orale <eos>', '<sos> no <eos>', '<sos> ya <eos>', '<sos> no <eos>', '<sos> fuera <eos>']\n"
     ]
    }
   ],
   "source": [
    "eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\n",
    "spa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]\n",
    "\n",
    "print(eng_sentences[:5])\n",
    "print(spa_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    words = [word for sentence in sentences for word in sentence.split()]\n",
    "    word_count = Counter(words)\n",
    "    \n",
    "    sorted_word_counts = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    \n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    \n",
    "    return word2idx, idx2word\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\n",
    "spa_word2idx, spa_idx2word = build_vocab(spa_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabularies sizes: 27933, 47339\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_word2idx)\n",
    "spa_vocab_size = len(spa_word2idx)\n",
    "\n",
    "print(f'Vocabularies sizes: {eng_vocab_size}, {spa_vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngSpaDataset(Dataset):\n",
    "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
    "        self.eng_sentences = eng_sentences\n",
    "        self.spa_sentences = spa_sentences\n",
    "        self.eng_word2idx = eng_word2idx\n",
    "        self.spa_word2idx = spa_word2idx\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.eng_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        eng_sentence = self.eng_sentences[idx]\n",
    "        spa_sentence = self.spa_sentences[idx]\n",
    "        \n",
    "        # return tokens idxs\n",
    "        eng_idxs = [ self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
    "        spa_idxs = [ self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
    "        \n",
    "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    eng_batch, spa_batch = zip(*batch)\n",
    "    \n",
    "    eng_batch =  [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
    "    spa_batch =  [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
    "    \n",
    "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
    "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return eng_batch, spa_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_function, optimizer, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
    "            eng_batch = eng_batch.to(device)\n",
    "            spa_batch = spa_batch.to(device)\n",
    "            \n",
    "            # Decoder preprocessing\n",
    "            target_input = spa_batch[:, :-1]                        # <eos>\n",
    "            target_output = spa_batch[:, 1:].contiguous().view(-1)  # <sos>\n",
    "            \n",
    "            # Zero grads\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # run model\n",
    "            output = model(eng_batch, target_input)\n",
    "            output = output.view(-1, output.size(-1)) \n",
    "            \n",
    "            # loss\n",
    "            loss = loss_function(output, target_output)\n",
    "            \n",
    "            #gradient and update parameters\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # print loss per epoch\n",
    "        print(f'Epoch {epoch + 1}/{epochs}: Loss: {total_loss / len(dataloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model=512,\n",
    "                    n_head=8, \n",
    "                    dim_feedforward=2048,\n",
    "                    num_layers=6,\n",
    "                    input_vocab_size=eng_vocab_size,\n",
    "                    target_vocab_size=spa_vocab_size,\n",
    "                    max_seq_len=MAX_SEQ_LEN,\n",
    "                    dropout=0.1,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss: 3.5323983691421486\n",
      "Epoch 2/10: Loss: 2.152894883446522\n",
      "Epoch 3/10: Loss: 1.6524279881515214\n",
      "Epoch 4/10: Loss: 1.3204779436350544\n",
      "Epoch 5/10: Loss: 1.0641821615947218\n",
      "Epoch 6/10: Loss: 0.8580102765675641\n",
      "Epoch 7/10: Loss: 0.6916081658819785\n",
      "Epoch 8/10: Loss: 0.5674362089942669\n",
      "Epoch 9/10: Loss: 0.47832796518428566\n",
      "Epoch 10/10: Loss: 0.4168320750581745\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, loss_function, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices(sentence, word2idx):\n",
    "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
    "\n",
    "def indices_to_sentence(indices, idx2word):\n",
    "    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])\n",
    "\n",
    "def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    model.eval()\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input_indices = sentence_to_indices(sentence, eng_word2idx)\n",
    "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    # Initialize the target tensor with <sos> token\n",
    "    tgt_indices = [spa_word2idx['<sos>']]\n",
    "    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(input_tensor, tgt_tensor)\n",
    "            output = output.squeeze(0)\n",
    "            next_token = output.argmax(dim=-1)[-1].item()\n",
    "            tgt_indices.append(next_token)\n",
    "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "            if next_token == spa_word2idx['<eos>']:\n",
    "                break\n",
    "\n",
    "    return indices_to_sentence(tgt_indices, spa_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    for sentence in sentences:\n",
    "        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
    "        print(f'Input sentence: {sentence}')\n",
    "        print(f'Traducción: {translation}')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Hello, how are you?\n",
      "Traducción: <sos> hola como estas <eos>\n",
      "\n",
      "Input sentence: I am learning artificial intelligence.\n",
      "Traducción: <sos> estoy aprendiendo inteligencia artificial <eos>\n",
      "\n",
      "Input sentence: Artificial intelligence is great.\n",
      "Traducción: <sos> la inteligencia artificial es genial <eos>\n",
      "\n",
      "Input sentence: Good night!\n",
      "Traducción: <sos> buenas noches <eos>\n",
      "\n",
      "Input sentence: The quick brown fox jumps over the lazy dog.\n",
      "Traducción: <sos> el rapido zorro marron salta por encima del perro vago <eos>\n",
      "\n",
      "Input sentence: Artificial intelligence is transforming industries rapidly.\n",
      "Traducción: <sos> la inteligencia artificial es una inteligencia artificial de las industrias rapidamente <eos>\n",
      "\n",
      "Input sentence: She sells seashells by the seashore.\n",
      "Traducción: <sos> ella vende conchas en la costa <eos>\n",
      "\n",
      "Input sentence: Despite the rain, the soccer match continued uninterrupted.\n",
      "Traducción: <sos> pese a pesar de la lluvia el partido de futbol <eos>\n",
      "\n",
      "Input sentence: Quantum computing will revolutionize technology in the coming decades.\n",
      "Traducción: <sos> la tecnologia cuantica llega a tecnologia de la empresa cuantica <eos>\n",
      "\n",
      "Input sentence: The chef cooked an amazing dinner for the guests.\n",
      "Traducción: <sos> el chef cocino una cena para los huespedes <eos>\n",
      "\n",
      "Input sentence: Travel broadens the mind and enriches the soul.\n",
      "Traducción: <sos> la mente reunio el alma y la seguridad <eos>\n",
      "\n",
      "Input sentence: Never underestimate the power of a simple act of kindness.\n",
      "Traducción: <sos> nunca subestimes el poder de un simple poder <eos>\n",
      "\n",
      "Input sentence: The new movie received excellent reviews from critics.\n",
      "Traducción: <sos> la nueva pelicula recibio un monton de peliculas excelente <eos>\n",
      "\n",
      "Input sentence: He couldn't remember where he had left his keys.\n",
      "Traducción: <sos> no se podia acordar de donde habia dejado las llaves <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example sentences to test the translator\n",
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I am learning artificial intelligence.\",\n",
    "    \"Artificial intelligence is great.\",\n",
    "    \"Good night!\", \n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming industries rapidly.\",\n",
    "    \"She sells seashells by the seashore.\",\n",
    "    \"Despite the rain, the soccer match continued uninterrupted.\",\n",
    "    \"Quantum computing will revolutionize technology in the coming decades.\",\n",
    "    \"The chef cooked an amazing dinner for the guests.\",\n",
    "    \"Travel broadens the mind and enriches the soul.\",\n",
    "    \"Never underestimate the power of a simple act of kindness.\",\n",
    "    \"The new movie received excellent reviews from critics.\",\n",
    "    \"He couldn't remember where he had left his keys.\"   \n",
    "    \n",
    "]\n",
    "\n",
    "# Assuming the model is trained and loaded\n",
    "# Set the device to 'cpu' or 'cuda' as needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Evaluate translations\n",
    "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
